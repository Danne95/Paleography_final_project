{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from consts import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n",
            "Physical devices cannot be modified after being initialized\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-06 13:36:50.856159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:50.866349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:50.867191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:50.869703: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-06 13:36:50.870082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:50.870936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:50.871751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:51.493636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:51.494519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:51.495326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 13:36:51.496140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n"
          ]
        }
      ],
      "source": [
        "#GPU initialization for cnn learning\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ecXQMMivaduI"
      },
      "outputs": [],
      "source": [
        "#Images folders for train and testing\n",
        "train_folder = '/home/historicalmanuscripts/Images_v2/train_otsu_3channels'\n",
        "blind_folder = '/home/historicalmanuscripts/Images_v2/blind_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gzVO84CSTu5U"
      },
      "outputs": [],
      "source": [
        "# Creating generators\n",
        "# Train data set\n",
        "train_file_names = np.array(os.listdir(train_folder))\n",
        "class_labels = [const_classes[img.split(\"_\")[0]] for img in train_file_names]\n",
        "subclass_labels = [const_subclasses[img.split(\"_\")[1]] for img in train_file_names]\n",
        "\n",
        "# Split train to train and validation\n",
        "C_train_data, C_valid_data, C_train_classes, C_valid_classes = train_test_split(train_file_names, class_labels, shuffle = True, stratify=class_labels)\n",
        "SC_train_data, SC_valid_data, SC_train_classes, SC_valid_classes = train_test_split(train_file_names, subclass_labels, shuffle = True, stratify=subclass_labels)\n",
        "\n",
        "# Creating generators instances\n",
        "train_generator_C = Batch_Generator(train_folder, C_train_data, C_train_classes, batch_size)\n",
        "train_generator_SC = Batch_Generator(train_folder, SC_train_data, SC_train_classes, batch_size)\n",
        "\n",
        "validation_generator_C = Batch_Generator(train_folder, C_valid_data, C_valid_classes, batch_size)\n",
        "validation_generator_SC = Batch_Generator(train_folder, SC_valid_data, SC_valid_classes, batch_size)\n",
        "\n",
        "# Final generator instances w/o validation split\n",
        "final_generator_C = Batch_Generator(train_folder, train_file_names, class_labels, batch_size)\n",
        "final_generator_SC = Batch_Generator(train_folder, train_file_names, subclass_labels, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Generators for blind evalutation\n",
        "\n",
        "blind_file_names = np.array(os.listdir(blind_folder))\n",
        "blind_class_labels = np.array([const_classes[img.split(\"_\")[0]] for img in blind_file_names if 'jpg' in img])\n",
        "blind_subclass_labels = np.array([const_subclasses[img.split(\"_\")[1]] for img in blind_file_names if 'jpg' in img])\n",
        "\n",
        "blind_generator_C = Batch_Generator(blind_folder, blind_file_names, blind_class_labels, batch_size)\n",
        "blind_generator_SC = Batch_Generator(blind_folder, blind_file_names, blind_subclass_labels, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 2.395328338475099, 1: 14.97245179063361, 2: 2.6668302257114815, 3: 4.334130781499202, 4: 5.112888052681091, 5: 1.3996909605974763}\n",
            "{0: 4.465899753492193, 1: 1.1264248704663213, 2: 1.125724937862469}\n"
          ]
        }
      ],
      "source": [
        "#Class weight distribution for weighted learing\n",
        "\n",
        "total = len(train_file_names)\n",
        "class_weights = {c:(1 / class_labels.count(c)) * (total / 2.0) for c in const_classes.values()}\n",
        "subclass_weights = {c:(1 / subclass_labels.count(c)) * (total / 2.0) for c in const_subclasses.values()}\n",
        "\n",
        "print(class_weights)\n",
        "print(subclass_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#History dict and results for plotting\n",
        "final_history_dict = {}\n",
        "results = {'class':{}, 'subclass':{}}\n",
        "data = preprocess_data(blind_folder,'inv_otsu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNetV2B2\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 400, 400, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetv2-b2 (Function  (None, 13, 13, 1408)     8769374   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1408)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 8454      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,777,828\n",
            "Trainable params: 8,454\n",
            "Non-trainable params: 8,769,374\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "340/340 [==============================] - 152s 419ms/step - loss: 0.8216 - accuracy: 0.7227\n",
            "Epoch 2/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.4990 - accuracy: 0.8435\n",
            "Epoch 3/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.4029 - accuracy: 0.8730\n",
            "Epoch 4/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.3454 - accuracy: 0.8936\n",
            "Epoch 5/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.3066 - accuracy: 0.9059\n",
            "Epoch 6/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 0.2777 - accuracy: 0.9138\n",
            "Epoch 7/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.2535 - accuracy: 0.9245\n",
            "Epoch 8/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.2354 - accuracy: 0.9323\n",
            "Epoch 9/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.2196 - accuracy: 0.9369\n",
            "Epoch 10/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.2067 - accuracy: 0.9395\n",
            "Epoch 11/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1940 - accuracy: 0.9455\n",
            "Epoch 12/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1842 - accuracy: 0.9483\n",
            "Epoch 13/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1755 - accuracy: 0.9506\n",
            "Epoch 14/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1657 - accuracy: 0.9533\n",
            "Epoch 15/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1589 - accuracy: 0.9570\n",
            "Epoch 16/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1528 - accuracy: 0.9593\n",
            "Epoch 17/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1462 - accuracy: 0.9595\n",
            "Epoch 18/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1401 - accuracy: 0.9632\n",
            "Epoch 19/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1357 - accuracy: 0.9631\n",
            "Epoch 20/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.1304 - accuracy: 0.9662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-06 14:27:47.987004: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: EfficientNetV2B2_final_20_dropout02/assets\n"
          ]
        }
      ],
      "source": [
        "#EfficientNetV2B2\n",
        "#20 ephocs\n",
        "#non weighted classes\n",
        "#dropout 0.2\n",
        "model = 'EfficientNetV2B2'\n",
        "print(model)\n",
        "m = create_model(model,input_shape,originNum)\n",
        "m.summary()\n",
        "final_history_dict[model] = m.fit(x=final_generator_C,\n",
        "                          epochs=20)\n",
        "m.save(model+\"_final_20_dropout02\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNetV2B2\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 400, 400, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetv2-b2 (Function  (None, 13, 13, 1408)     8769374   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 1408)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 8454      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,777,828\n",
            "Trainable params: 8,454\n",
            "Non-trainable params: 8,769,374\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "340/340 [==============================] - 148s 412ms/step - loss: 2.8344 - accuracy: 0.6956\n",
            "Epoch 2/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 1.7395 - accuracy: 0.8236\n",
            "Epoch 3/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 1.4003 - accuracy: 0.8586\n",
            "Epoch 4/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 1.2009 - accuracy: 0.8807\n",
            "Epoch 5/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 1.0618 - accuracy: 0.8931\n",
            "Epoch 6/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 0.9510 - accuracy: 0.9047\n",
            "Epoch 7/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.8818 - accuracy: 0.9140\n",
            "Epoch 8/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 0.8050 - accuracy: 0.9212\n",
            "Epoch 9/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 0.7504 - accuracy: 0.9289\n",
            "Epoch 10/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.6988 - accuracy: 0.9324\n",
            "Epoch 11/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.6545 - accuracy: 0.9374\n",
            "Epoch 12/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.6200 - accuracy: 0.9401\n",
            "Epoch 13/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.5868 - accuracy: 0.9443\n",
            "Epoch 14/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.5632 - accuracy: 0.9464\n",
            "Epoch 15/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.5353 - accuracy: 0.9489\n",
            "Epoch 16/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.5077 - accuracy: 0.9528\n",
            "Epoch 17/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.4868 - accuracy: 0.9538\n",
            "Epoch 18/20\n",
            "340/340 [==============================] - 140s 411ms/step - loss: 0.4661 - accuracy: 0.9565\n",
            "Epoch 19/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 0.4492 - accuracy: 0.9583\n",
            "Epoch 20/20\n",
            "340/340 [==============================] - 140s 412ms/step - loss: 0.4336 - accuracy: 0.9596\n",
            "INFO:tensorflow:Assets written to: EfficientNetV2B2_final_20_dropout02_weighted/assets\n"
          ]
        }
      ],
      "source": [
        "#EfficientNetV2B2\n",
        "#20 ephocs\n",
        "#weighted classes\n",
        "#dropout 0.2\n",
        "model = 'EfficientNetV2B2'\n",
        "print(model)\n",
        "m = create_model(model,input_shape,originNum)\n",
        "m.summary()\n",
        "final_history_dict[model] = m.fit(x=final_generator_C,\n",
        "                          epochs=20,\n",
        "                          class_weight = class_weights)\n",
        "m.save(model+\"_final_20_dropout02_weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xception\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 400, 400, 3)]     0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 400, 400, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 400, 400, 3)      0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " xception (Functional)       (None, 13, 13, 2048)      20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 6147      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,867,627\n",
            "Trainable params: 6,147\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "340/340 [==============================] - 311s 900ms/step - loss: 0.6415 - accuracy: 0.7177\n",
            "Epoch 2/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.4846 - accuracy: 0.8086\n",
            "Epoch 3/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.4245 - accuracy: 0.8362\n",
            "Epoch 4/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.3890 - accuracy: 0.8520\n",
            "Epoch 5/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3658 - accuracy: 0.8605\n",
            "Epoch 6/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3464 - accuracy: 0.8727\n",
            "Epoch 7/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3300 - accuracy: 0.8770\n",
            "Epoch 8/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3171 - accuracy: 0.8816\n",
            "Epoch 9/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3042 - accuracy: 0.8920\n",
            "Epoch 10/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2938 - accuracy: 0.8947\n",
            "Epoch 11/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2856 - accuracy: 0.8963\n",
            "Epoch 12/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2791 - accuracy: 0.9006\n",
            "Epoch 13/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2684 - accuracy: 0.9070\n",
            "Epoch 14/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2620 - accuracy: 0.9087\n",
            "Epoch 15/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2551 - accuracy: 0.9110\n",
            "Epoch 16/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2506 - accuracy: 0.9141\n",
            "Epoch 17/20\n",
            "340/340 [==============================] - 304s 893ms/step - loss: 0.2456 - accuracy: 0.9154\n",
            "Epoch 18/20\n",
            "340/340 [==============================] - 304s 893ms/step - loss: 0.2392 - accuracy: 0.9175\n",
            "Epoch 19/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2361 - accuracy: 0.9195\n",
            "Epoch 20/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.2314 - accuracy: 0.9216\n",
            "INFO:tensorflow:Assets written to: Xception_SC_final_20_dropout02/assets\n"
          ]
        }
      ],
      "source": [
        "#Xception\n",
        "#20 ephocs\n",
        "#non weighted classes\n",
        "#dropout 0.2\n",
        "model = 'Xception'\n",
        "print(model)\n",
        "m = create_model(model,input_shape,styleNum)\n",
        "m.summary()\n",
        "final_history_dict[model+'SC'] = m.fit(x=final_generator_SC,\n",
        "                          epochs=20)\n",
        "m.save(model+\"_SC_final_20_dropout02\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xception\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 400, 400, 3)]     0         \n",
            "                                                                 \n",
            " tf.math.truediv_1 (TFOpLamb  (None, 400, 400, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_1 (TFOpLam  (None, 400, 400, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " xception (Functional)       (None, 13, 13, 2048)      20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d_4   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 6147      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,867,627\n",
            "Trainable params: 6,147\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "340/340 [==============================] - 310s 895ms/step - loss: 1.0106 - accuracy: 0.6694\n",
            "Epoch 2/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.7583 - accuracy: 0.7703\n",
            "Epoch 3/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.6660 - accuracy: 0.8042\n",
            "Epoch 4/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.6113 - accuracy: 0.8205\n",
            "Epoch 5/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.5741 - accuracy: 0.8311\n",
            "Epoch 6/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.5359 - accuracy: 0.8466\n",
            "Epoch 7/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.5123 - accuracy: 0.8541\n",
            "Epoch 8/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.4923 - accuracy: 0.8617\n",
            "Epoch 9/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.4711 - accuracy: 0.8678\n",
            "Epoch 10/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.4557 - accuracy: 0.8738\n",
            "Epoch 11/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.4381 - accuracy: 0.8843\n",
            "Epoch 12/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.4244 - accuracy: 0.8879\n",
            "Epoch 13/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.4147 - accuracy: 0.8905\n",
            "Epoch 14/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.4030 - accuracy: 0.8932\n",
            "Epoch 15/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3908 - accuracy: 0.8974\n",
            "Epoch 16/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3812 - accuracy: 0.8983\n",
            "Epoch 17/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3756 - accuracy: 0.9027\n",
            "Epoch 18/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3656 - accuracy: 0.9066\n",
            "Epoch 19/20\n",
            "340/340 [==============================] - 304s 895ms/step - loss: 0.3560 - accuracy: 0.9080\n",
            "Epoch 20/20\n",
            "340/340 [==============================] - 304s 894ms/step - loss: 0.3531 - accuracy: 0.9077\n",
            "INFO:tensorflow:Assets written to: Xception_SC_final_20_dropout02_weighted/assets\n"
          ]
        }
      ],
      "source": [
        "#Xception\n",
        "#20 ephocs\n",
        "#weighted classes\n",
        "#dropout 0.2\n",
        "model = 'Xception'\n",
        "print(model)\n",
        "m = create_model(model,input_shape,styleNum)\n",
        "m.summary()\n",
        "final_history_dict[model+'SC'] = m.fit(x=final_generator_SC,\n",
        "                          epochs=20,\n",
        "                          class_weight = subclass_weights)\n",
        "m.save(model+\"_SC_final_20_dropout02_weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNetV2B2_final_20_dropout02  class:\n",
            "\n",
            "Image 171, Stats: 80/172\n",
            "\n",
            "EfficientNetV2B2_final_20_dropout02_weighted  class:\n",
            "\n",
            "Image 171, Stats: 83/172\n",
            "\n",
            "Xception_SC_final_20_dropout02  class:\n",
            "\n",
            "Image 171, Stats: 107/172\n",
            "\n",
            "Xception_SC_final_20_dropout02_weighted  class:\n",
            "\n",
            "Image 171, Stats: 99/172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = 'EfficientNetV2B2_final_20_dropout02'\n",
        "print(model,' class:\\n')\n",
        "results['class'][model] = evaluate_model(data, tf.keras.models.load_model(model),'class', True)\n",
        "model = 'EfficientNetV2B2_final_20_dropout02_weighted'\n",
        "print(model,' class:\\n')\n",
        "results['class'][model] = evaluate_model(data, tf.keras.models.load_model(model),'class', True)\n",
        "\n",
        "\n",
        "model = 'Xception_SC_final_20_dropout02'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)\n",
        "model = 'Xception_SC_final_20_dropout02_weighted'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNetV2B2_final  class:\n",
            "\n",
            "Image 171, Stats: 94/172\n",
            "\n",
            "Xception_SC_final  class:\n",
            "\n",
            "Image 171, Stats: 105/172\n",
            "\n",
            "EfficientNetV2B2_final_50  class:\n",
            "\n",
            "Image 171, Stats: 90/172\n",
            "\n",
            "Xception_SC_final_50  class:\n",
            "\n",
            "Image 171, Stats: 110/172\n",
            "\n",
            "EfficientNetV2B2_final_100  class:\n",
            "\n",
            "Image 171, Stats: 84/172\n",
            "\n",
            "Xception_SC_final_100  class:\n",
            "\n",
            "Image 171, Stats: 101/172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = 'EfficientNetV2B2_final'\n",
        "print(model,' class:\\n')\n",
        "results['class'][model] = evaluate_model(data, tf.keras.models.load_model(model),'class', True)\n",
        "model = 'Xception_SC_final'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)\n",
        "model = 'EfficientNetV2B2_final_50'\n",
        "print(model,' class:\\n')\n",
        "results['class'][model] = evaluate_model(data, tf.keras.models.load_model(model),'class', True)\n",
        "model = 'Xception_SC_final_50'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)\n",
        "model = 'EfficientNetV2B2_final_100'\n",
        "print(model,' class:\\n')\n",
        "results['class'][model] = evaluate_model(data, tf.keras.models.load_model(model),'class', True)\n",
        "model = 'Xception_SC_final_100'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EfficientNetV2B2_final_100_weighted  class:\n",
            "\n",
            "Image 171, Stats: 23/172\n",
            "\n",
            "Xception_SC_final_100_weighted  class:\n",
            "\n",
            "Image 171, Stats: 102/172\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = 'EfficientNetV2B2_final_100_weighted'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)\n",
        "model = 'Xception_SC_final_100_weighted'\n",
        "print(model,' class:\\n')\n",
        "results['subclass'][model] = evaluate_model(data, tf.keras.models.load_model(model),'subclass', True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of paleo_transfer_learning.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
